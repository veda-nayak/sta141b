---
title: "Reading Solar Data -- Part 2"
author: "Veda Nayak"
date: "2025-04-16"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
dir = "C:/cygwin64/home/vedan/Code/sta141b/"
source(paste(dir, "/assignment1part2code.R", sep = ""))

```

# Overview
The goal of this assignment is to extract information from the climate data in the .stat files and generate four tables.

- Monthly Statistics for Relative Humidity
    - 11 Columns: Month, Maximum, Minimum, Daily Average, DayTime Average, NightTime Average, Max Day, Max Hour, Min Day, Min Hour,Location
    - 12 Rows: One for each month
- Monthly Statistics for Solar Radiation
     - 7 Columns: Month, Direct Average, Direct Max, Direct Max Day, Diffuse Average, Global Average, Location
     - 12 Rows: One for each month
- Average Hourly Statistics for Opaque Sky Cover
    - 4 columns: Month, Hour, Temperature, Location
    - 288 Rows: One for each month * hours in a day
- Psychrometric Chart Data
  - 3 columns: Dewpoint, Dry Bulb Temperature, Location
  - The number of rows are dependent on the number of dewpoint-dryBulb combinations the average temperature was taken at. 
  
I also added a "location" column to each file to make it easier to orient the viewer / person working with the data.

# PART 2 

## Step 1: Extract lines of text corresponding to the tables
I first created functions that would help me extract the tables I needed (their respective lines). I created the following functions in this pursuit. 

- getBlocks: Creates blocks of text that start with " - " and end at the line before the next " - ".
- tableStarts: Uses the getBlocks() and findTitles() functionsinds the block indices corresponding to the start of the tables we are interested in.
- findTitles: Uses grepl() to checks if a given block corresponds to a table we are after.
- getTables: Uses the getBlocks() and tableStarts() functions to extract all the lines needed for the respective tables.

## Step 2: Extracting Desired Table Data from One Dataset and Transforming the Dataframe
I worked with the "USA_CA_UC-Davis-University.AP.720576_TMYx.2009-2023.stat" data. I made four functions to do this, one for each table. There was enough variability in the dataset that made me think that four functions would be best. 

- getAvgHourSkyCount: "Average Hourly Statistics for Opaque Sky Cover" dataframe generation
- getHumid: "Monthly Statistics for Relative Humidity" dataframe generation
- getPsyched: "Psychrometric Chart Data" dataframe generation
- getSolarRad: "Monthly Statistics for Solar Radiation" dataframe generation

The workflow for the *getHumid* and *getSolarRad* is as such:

 1. Use getTables() to get a list of tables.
 2. Extract the table I was after. 
- Since the order of the tables was location specific on the document, and there was a consistant ordering of tables, getTables() outputs the files in this order: "Monthly Statistics for Relative Humidity", "Monthly Statistics for Solar Radiation", "Average Hourly Statistics for Opaque Sky Cover", "Psychrometric Chart Data". I extracted the correct table based on the numerical positioning in the tables list. 
 3. Transfer the lines to a text connection to make it workable when using the read.delim() function.
 4. Use read.delim() to import the lines into a dataframe. The lines use tab separation.
 5. Make the 'Day' columns more specific
 6. Make a row that contains the months
 7. Transpose the data
 8. SKIP IN *getSolarRad*: Split the Day:Hour column by the ':' and add the result into a new column

The workflow for the *getPsyched* and *getAvgHourSkyCount* is as such:

 1. Use getTables() to get a list of tables.
 2. Extract the table I was after. 
- Since the order of the tables was location specific on the document, and there was a consistant ordering of tables, getTables() outputs the files in this order: "Monthly Statistics for Relative Humidity", "Monthly Statistics for Solar Radiation", "Average Hourly Statistics for Opaque Sky Cover", "Psychrometric Chart Data". I extracted the correct table based on the numerical positioning in the tables list. 
 3. Transfer the lines to a text connection to make it workable when using the read.delim() function.
 4. Use read.delim() to import the lines into a dataframe. The lines use tab separation.
 5. Remove extra lines and rename the id column.
 6. Use  melt() from the reshape2 library to move the columns into rows
 7. Final dataframe cleanup (removing whitespace, etc.)
 

## Step 3: Implimenting the functions across all files
I put all four dataframe generation functions into a function that would output a list of dataframes to make it easier to apply across a list of files. 

- getDataframes: Generate a list of the four data frames I am interested in for this assignment. 


## Generated Dataframes

Since I developed the functions using the Davis data, I wanted to validate my results using data from another location. I chose to look at the Yosemite dataset for validation. 

Yosemite - Monthly Statistics for Relative Humidity:
```{r echo=TRUE}
head(yosemite_humid)
```


Yosemite - Monthly Statistics for Relative Solar Radiation:
```{r echo=TRUE}
head(yosemite_solar_rad)

```


Yosemite - Average Hourly Statistics for Opaque Sky Cover:
```{r echo=TRUE}
head(yosemite_sky_cov)
tail(yosemite_sky_cov)
```

Yosemite - Psychrometric Chart Data

```{r echo=TRUE}
head(yosemite_psych)
```



# Validation

## Monthly Statistics for Relative Humidity

### Check Dataframe and Column Class Expectations

*Check if the output is a dataframe:* 

```{r}
humid_class 
```
The output is a dataframe. 


*Check if dimensions align with expectations:*
```{r, Yosemite Monthly Statistics for Relative Humidity}
dim_humid
```
We expected an 12 x 11 dataframe, so this dataframe aligns with our expectations. 


*Check Column Type*
I wanted to confirm that the month and location were a character type vectors and that all others were integer vectors. 

```{r}
humid_classes
```
All columns have a class consistant with what we expected

### Graph Data to Gauge Validity

```{r}

yosemite_humid_graph_humidity_readings

```
The maximum humidity is consistently greater than the minimum humidity, which is logical. 
The daily average seems to sit right in the middle of the DayTime and NightTime averages, which is logical. 
The humidity dips in the summer months which is logical since it is generally less wet / hotter in the summer. 


```{r}
yosemite_humid_graph_hour_readings
```
The hour that corresponds to the maximum humidity is at night. This is consistent with the data in the previous graph showing that the nighttime average was higher than the daytime average. 


## Monthly Statistics for Relative Solar Radiation

*Check if the output is a dataframe:* 

```{r}
class_solar 
```
The output is a dataframe. 


*Check if dimensions align with expectations:*
```{r}
dim_solar 
```
We expected an 12 x 7 dataframe, so this dataframe aligns with our expectations. 

*Check Column Type*
I wanted to confirm that the month and location were a character type vectors and that all others were integer vectors. 

```{r}
solar_classes 
```
All columns have a class consistent with what we expected.


### Graph Data to Gauge Validity


```{r}
yosemite_solar_rad_graph
```
The maximum humidity is consistently greater than the minimum humidity, which is logical. 
The daily average seems to sit right in the middle of the DayTime and NightTime averages, which is logical. 
The solar radiation increases in the summer months which is logical since it is sunnier in the summer (more solar radiation). 


## Average Hourly Statistics for Opaque Sky Cover
*Check if the output is a dataframe:* 

```{r}
class_sky 
```
The output is a dataframe. 


*Check if dimensions align with expectations:*
```{r}
dim_sky
```
We expected an 288 x 4 dataframe, so this dataframe aligns with our expectations. 

*Check Column Type*
I wanted to confirm that the month and location were a character type vectors, the percent covered was numeric, and the month was a factor or character vector. 

```{r}
sky_classes
```
All columns have a class consistent with what we expected.

### Graph Data to Gauge Validity

I thought comparing the sky coverage data to Davis would help contextualize my results. 
```{r}
yosemite_davis_sky_cov_graph
```
Yosemite consistently has higher sky coverage percentages as compared to Davis. This makes sense since Yosemite experiences more snow and rain than Davis does, especially in the summer months. 
The percent opaque sky cover also decreases in the summer months, which makes sense considering that it is generally sunnier (less cloud coverage) in the summer. 



## Psychrometric Chart Data

*Check if the output is a dataframe:* 

```{r}
class_psych 
```
The output is a dataframe. 


*Check if dimensions align with expectations:*
```{r}
dim_psych
```
We expected an 40 x 4 dataframe, so this dataframe aligns with our expectations. 

*Check Column Type*
I wanted to confirm that the month and location were a character type vectors, the temperature was a numeric vector, and that the dewpoint and dry_bulb columns were charecter / factor vectors. 

```{r}
psych_classes
```
All columns have a class consistent with what we expected.

### Graph Data to Gauge Validity

```{r}
yosemite_psych_graph
```


# Acknowledgments

[Step 2 - Step 6, transforming the data: melt() function in 'reshape2' library]("https://stackoverflow.com/questions/32390886/i-want-to-turn-column-names-into-an-identifying-column-in-r")

[Step 2: Removeing whitespace in the Relative Humidity dataframe]("https://stackoverflow.com/questions/34591329/remove-white-space-from-a-data-frame-column-and-add-path")

[Validation - Connecting points in ggplot]("https://stackoverflow.com/questions/8592585/combine-points-with-lines-with-ggplot2")

[Validation - Ordering the x-axis]("https://stackoverflow.com/questions/12774210/how-do-you-specifically-order-ggplot2-x-axis-instead-of-alphabetical-order")


